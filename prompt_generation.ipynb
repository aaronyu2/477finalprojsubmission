{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/accts/amy23/.local/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.11/site-packages (from datasets) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/lib64/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3.11/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /usr/lib64/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/lib64/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/accts/amy23/.local/lib/python3.11/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.11/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3.11/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib64/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib64/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/lib64/python3.11/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/accts/amy23/.local/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/accts/amy23/.local/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/accts/amy23/.local/lib/python3.11/site-packages (4.39.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3.11/site-packages (from transformers) (3.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/accts/amy23/.local/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/accts/amy23/.local/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib64/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/lib64/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.11/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/accts/amy23/.local/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/accts/amy23/.local/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/accts/amy23/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/accts/amy23/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting vertexai\n",
      "  Downloading vertexai-1.48.0-py3-none-any.whl (7.3 kB)\n",
      "Collecting google-cloud-aiplatform[all]==1.48.0\n",
      "  Downloading google_cloud_aiplatform-1.48.0-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: google-cloud-aiplatform 1.48.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/lib/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (2.11.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/lib/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (2.28.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/lib64/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (3.19.6)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/lib/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (23.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/lib/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (2.13.0)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-3.20.1-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.7/333.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: shapely<3.0.0dev in /usr/lib64/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (1.8.5.post1)\n",
      "Requirement already satisfied: pydantic<3 in /home/accts/amy23/.local/lib/python3.11/site-packages (from google-cloud-aiplatform[all]==1.48.0->vertexai) (2.7.0)\n",
      "Collecting docstring-parser<1\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (2.28.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/lib64/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (1.48.4)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (1.48.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform[all]==1.48.0->vertexai) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform[all]==1.48.0->vertexai) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform[all]==1.48.0->vertexai) (2.8.2)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/lib64/python3.11/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform[all]==1.48.0->vertexai) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/accts/amy23/.local/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform[all]==1.48.0->vertexai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/accts/amy23/.local/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform[all]==1.48.0->vertexai) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/accts/amy23/.local/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform[all]==1.48.0->vertexai) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/lib/python3.11/site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform[all]==1.48.0->vertexai) (1.26.18)\n",
      "Installing collected packages: proto-plus, docstring-parser, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform, vertexai\n",
      "Successfully installed docstring-parser-0.16 google-cloud-aiplatform-1.48.0 google-cloud-bigquery-3.20.1 google-cloud-resource-manager-1.12.3 grpc-google-iam-v1-0.13.0 proto-plus-1.23.0 vertexai-1.48.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print\n",
    "from pprint import pprint\n",
    "# Datasets load_dataset function\n",
    "from datasets import load_dataset\n",
    "# Transformers Autokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# Standard PyTorch DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image as PILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_images(images):\n",
    "    if len(images) == 1:\n",
    "        return images[0]\n",
    "    if len(images) < 1:\n",
    "        return None\n",
    "    max_height = 0\n",
    "    total_width = 0\n",
    "    for image in images:\n",
    "        width, height = image.size\n",
    "        print(width, height)\n",
    "        max_height = max(height, max_height)\n",
    "        total_width += width\n",
    "    to_return = PILImage.new(\"RGB\", (total_width, max_height))\n",
    "    curr_x = 0\n",
    "    for image in images:\n",
    "        to_return.paste(image, (curr_x, 0))\n",
    "        curr_x += image.size[0]\n",
    "    # to_return.save(\"out.png\")\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cs477-final-project/.conda/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for HUPD/hupd contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/HUPD/hupd\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 14.7k/14.7k [00:00<00:00, 20.9MB/s]\n",
      "Downloading readme: 100%|██████████| 10.9k/10.9k [00:00<00:00, 17.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset with config: PatentsConfig(name='sample', version=0.0.0, data_dir='sample', data_files={'train': ['https://huggingface.co/datasets/HUPD/hupd/blob/main/hupd_metadata_2022-02-22.feather']}, description='Patent data from January 2016, for debugging')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 6.67M/6.67M [00:00<00:00, 58.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using metadata file: /home/ubuntu/.cache/huggingface/datasets/downloads/bac34b767c2799633010fa78ecd401d2eeffd62eff58abdb4db75829f8932710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 388M/388M [00:07<00:00, 53.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata file: /home/ubuntu/.cache/huggingface/datasets/downloads/bac34b767c2799633010fa78ecd401d2eeffd62eff58abdb4db75829f8932710\n",
      "Filtering train dataset by filing start date: 2016-01-01\n",
      "Filtering train dataset by filing end date: 2016-01-21\n",
      "Filtering val dataset by filing start date: 2016-01-22\n",
      "Filtering val dataset by filing end date: 2016-01-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 16153 examples [00:19, 821.42 examples/s] \n",
      "Generating validation split: 9094 examples [00:10, 855.30 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading is done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_dataset('HUPD/hupd',\n",
    "    name='sample',\n",
    "    data_files=\"https://huggingface.co/datasets/HUPD/hupd/blob/main/hupd_metadata_2022-02-22.feather\",\n",
    "    icpr_label=None,\n",
    "    train_filing_start_date='2016-01-01',\n",
    "    train_filing_end_date='2016-01-21',\n",
    "    val_filing_start_date='2016-01-22',\n",
    "    val_filing_end_date='2016-01-31',\n",
    ")\n",
    "\n",
    "print('Loading is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure prompts\n",
    "def generate_prompt_openai(patent_dict):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        messages: list to use as input to client.chat.completions.create()\n",
    "        target: groundtruth patent class label\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": \"Classify the following patent into a class in the International Patent Classification system. Answer with the a 4-character IPC class.\"},\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": patent_dict[\"abstract\"]\n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"TODO\"\n",
    "                } # you can also upload as a base64 images lol\n",
    "            }\n",
    "        ] } \n",
    "    ]\n",
    "    return messages, patent_dict[\"ipc_label\"][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'role': 'user', 'content': 'Classify the following patent into a class in the International Patent Classification system. Answer with the a 4-character IPC class.'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'The present invention relates to passive optical network (PON), and in particular, to an optical network terminal (ONT) in the PON system. In one embodiment, the optical network terminal includes a first interface coupled to a communications network, a second interface coupled to a network client and a processor including a memory coupled to the first interface and to the second interface, wherein the processor is capable of converting optical signals to electric signals, such that the network client can access the communications network.'}, {'type': 'image_url', 'image_url': {'url': 'TODO'}}]}], 'H04Q')\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt_openai(dataset_dict['train'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9FBYB6cq76llMSeFkiBokOb1gMm1r', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='G06K 19/00', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1713406347, model='gpt-4', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=227, total_tokens=234), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "# Azure prompts\n",
    "from openai import AzureOpenAI\n",
    "api_base = 'https://gerstein-westus.openai.azure.com/'\n",
    "api_key=\"b4521b5444d74d0284e9aa797245b25d\"\n",
    "deployment_name = 'gpt4-vision-preview'\n",
    "api_version = '2023-12-01-preview'\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,  \n",
    "    api_version=api_version,\n",
    "    base_url=f\"{api_base}openai/deployments/{deployment_name}/extensions\",\n",
    ")\n",
    "\n",
    "messages, ground_truth = generate_prompt_openai(dataset_dict['train'][0])\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=messages,\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLaVA prompts\n",
    "\n",
    "def generate_prompt_llava(patent_dict):\n",
    "    messages = [\n",
    "        {   \"id\": hash(str(patent_dict[\"patent_number\"])),\n",
    "            \"image\": \"TODO\",\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": \"<image>\\nClassify the following patent into a class in the International Patent Classification system. Answer with the a 4-character IPC class.\\n\" + patent_dict[\"abstract\"]\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": \"CLASSIFICATION\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages, patent_dict[\"ipc_label\"][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import Image as VertexImage\n",
    "import urllib.request\n",
    "import http.client\n",
    "import typing\n",
    "\n",
    "\n",
    "# Gemini prompts\n",
    "\n",
    "# based on input format of https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-multimodal-prompts\n",
    "\n",
    "def load_image_from_url(image_url):\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return VertexImage.from_bytes(image_bytes)\n",
    "\n",
    "def generate_prompt_gemini(patent_dict):\n",
    "    messages = [\n",
    "        load_image_from_url(\"https://patentimages.storage.googleapis.com/23/82/97/d28e8e17f1597a/US20140002137A1-20140102-D00002.png\"),\n",
    "        \"Classify the following patent into a class in the International Patent Classification system. Answer with the a 4-character IPC class.\\n\" + patent_dict[\"abstract\"]\n",
    "    ]\n",
    "    return messages, patent_dict[\"ipc_label\"][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<vertexai.generative_models._generative_models.Image object at 0x7f8db4195250>, 'Classify the following patent into a class in the International Patent Classification system. Answer with the a 4-character IPC class.\\nThe present invention relates to passive optical network (PON), and in particular, to an optical network terminal (ONT) in the PON system. In one embodiment, the optical network terminal includes a first interface coupled to a communications network, a second interface coupled to a network client and a processor including a memory coupled to the first interface and to the second interface, wherein the processor is capable of converting optical signals to electric signals, such that the network client can access the communications network.']\n",
      "candidates {\n",
      "  finish_reason: OTHER\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 379\n",
      "  total_token_count: 379\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "vertexai.init(project=\"cpsc477-patentpublic\", location=\"us-central1\")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "\n",
    "messages, ground_truth = generate_prompt_gemini(dataset_dict['train'][0])\n",
    "print(messages)\n",
    "\n",
    "response = model.generate_content(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Content has no parts.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[0;32m~/cs477-final-project/.conda/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1643\u001b[0m, in \u001b[0;36mGenerationResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidates:\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse has no candidates (and no text).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[0;32m~/cs477-final-project/.conda/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1712\u001b[0m, in \u001b[0;36mCandidate.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m-> 1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[0;32m~/cs477-final-project/.conda/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1783\u001b[0m, in \u001b[0;36mContent.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple content parts are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts:\n\u001b[0;32m-> 1783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent has no parts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mAttributeError\u001b[0m: Content has no parts."
     ]
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
